{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, tqdm, gym\n",
    "from gym.utils import seeding\n",
    "from gym.spaces.discrete import Discrete\n",
    "from gym.spaces import Box\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import matplotlib.pyplot as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relational Deep Reinforcement Learning\n",
    "The core idea behind RRL is to combine reinforcement learning with relational learning or Inductive\n",
    "Logic Programming, by **representing states, actions and policies using a first order (or relational)\n",
    "language**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers an RL task called Box-World from [[1]](https://arxiv.org/pdf/1806.01830.pdf), that explicitly targets relational reasoning, and demonstrates that agents with a capacity to produce relational representations using a **non-local computation based on attention** exhibit interesting generalization behaviors compared to those that do not.\n",
    "\n",
    "We can apply the agent to a difficult problem – the StarCraft II minigames – and achieve state-of-the-art performance on six minigames."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../graphics/Box-World.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                Box-World and StarCraft II tasks demand reasoning about entities and their relations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Moving from a propositional to a relational representation facilitates **generalization over goals, states, and actions**, exploiting knowledge learnt during an earlier learning phase.\n",
    "- A relational language also facilitates the use of background knowledge. Background knowledge can be provided by logical facts and rules relevant to the learning problem.\n",
    "\n",
    "In Box-World, one could use the predicate **above(S, A, B)** to indicate that **block A *is above* block B in state *S*** when specifying background knowledge.\n",
    "\n",
    "Such predicates can then be\n",
    "used during learning for blocks C and D, for example.\n",
    "\n",
    "\n",
    "**The representational language, background,\n",
    "and assumptions form the inductive bias**, which guides (and restricts) the search for good policies.\n",
    "The language (or declarative) bias determines the way concepts can be represented."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../graphics/RDRL.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoxWorld\n",
    "Box-World is a perceptually simple but combinatorially complex environment that requires abstract\n",
    "relational reasoning and planning. It consists of a **12×12 pixel room** with **keys and boxes randomly\n",
    "scattered**. The room also contains an agent, represented by a single dark gray pixel, which can move\n",
    "in four directions: up, down, left, right.\n",
    "\n",
    "Keys are represented by a single colored pixel. The agent can pick up a loose key (i.e., one not\n",
    "adjacent to any other colored pixel) by walking over it. Boxes are represented by two adjacent colored\n",
    "pixels – the pixel on the right represents the box’s lock and its color indicates which key can be used\n",
    "to open that lock; the pixel on the left indicates the content of the box which is inaccessible while\n",
    "the box is locked.\n",
    "\n",
    "To collect the content of a box the agent must first collect the key that opens the box (the one\n",
    "that matches the lock’s color) and walk over the lock, which makes the lock disappear. At this point\n",
    "the content of the box becomes accessible and can be picked up by the agent. Most boxes contain\n",
    "keys that, if made accessible, can be used to open other boxes. One of the boxes contains a gem,\n",
    "represented by a single white pixel. The goal of the agent is to collect the gem by unlocking the\n",
    "box that contains it and picking it up by walking over it. Keys that an agent has in possession are\n",
    "depicted in the input observation as a pixel in the top-left corner.\n",
    "\n",
    "In each level there is a unique sequence of boxes that need to be opened in order to reach the gem.\n",
    "Opening one wrong box (a distractor box) leads to a dead-end where the gem cannot be reached\n",
    "and the level becomes unsolvable.\n",
    "\n",
    "There are three user-controlled parameters that contribute to\n",
    "the difficulty of the level: \n",
    "- the number of boxes in the path to the goal (solution length);\n",
    "- the number of distractor branches;\n",
    "- the length of the distractor branches.\n",
    "\n",
    "In general, the task is computationally difficult for a few reasons:\n",
    "- A key can only be used once, so the agent must be able to reason about whether a particular box is along a distractor branch or along the solution path. \n",
    "\n",
    "- Keys and boxes appear in random locations in the room, emphasising a capacity to reason about keys and boxes based on their abstract relations, rather than based on their spatial positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_color = [128, 128, 128]\n",
    "\n",
    "action_space = {\n",
    "    0: (-1, 0),\n",
    "    1: (1,  0),\n",
    "    2: (0, -1),\n",
    "    3: (0,  1)\n",
    "}\n",
    "\n",
    "goal_color = [255, 255, 255]\n",
    "grid_color = [220, 220, 220]\n",
    "\n",
    "colors = {0: [  0,   0,   0],\n",
    "          1: [230, 190, 255],\n",
    "          2: [170, 255, 195],\n",
    "          3: [255, 250, 200],\n",
    "          4: [255, 216, 177],\n",
    "          5: [250, 190, 190],\n",
    "          6: [240,  50, 230],\n",
    "          7: [145,  30, 180],\n",
    "          8: [ 67,  99, 216],\n",
    "          9: [ 66, 212, 244],\n",
    "          10:[ 60, 180,  75],\n",
    "          11:[191, 239,  69],\n",
    "          12:[255, 255,  25],\n",
    "          13:[245, 130,  49],\n",
    "          14:[230,  25,  75],\n",
    "          15:[128,   0,   0],\n",
    "          16:[154,  99,  36],\n",
    "          17:[128, 128,   0],\n",
    "          18:[ 70, 153, 144],\n",
    "          19:[  0,   0, 117]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_pairs(pairs, n=12):\n",
    "    possibilities = set(range(1, n*(n-1)))\n",
    "    keys,locks = [],[]\n",
    "    for k in range(pairs):\n",
    "        key = random.sample(possibilities, 1)[0]\n",
    "        key_x, key_y = key//(n-1), key%(n-1)\n",
    "        \n",
    "        lock_x, lock_y = key_x, key_y + 1\n",
    "        \n",
    "        to_remove = [key_x * (n-1) + key_y] + \\\n",
    "                    [key_x * (n-1) + i + key_y for i in range(1, min(2, n - 2 - key_y) + 1)] + \\\n",
    "                    [key_x * (n-1) - i + key_y for i in range(1, min(2, key_y) + 1)]\n",
    "\n",
    "        possibilities -= set(to_remove)\n",
    "        \n",
    "        keys.append([key_x, key_y])\n",
    "        locks.append([lock_x, lock_y])\n",
    "        \n",
    "    agent_xy = random.sample(possibilities, 1)\n",
    "    possibilities -= set(agent_xy)\n",
    "    first_key = random.sample(possibilities, 1)\n",
    "\n",
    "    agent_xy = np.array([agent_xy[0]//(n-1), agent_xy[0]%(n-1)])\n",
    "    first_key = first_key[0]//(n-1), first_key[0]%(n-1)\n",
    "    return keys, locks, first_key, agent_xy\n",
    "\n",
    "def generate(n=12, goal_length=3, num_distractor=2, distractor_length=2, seed=None, verbose=False):\n",
    "    if seed is not None: random.seed(seed)\n",
    "\n",
    "    world_dic = {}\n",
    "    world = np.ones((n, n, 3)) * 220\n",
    "    goal_colors = random.sample(range(len(colors)), goal_length - 1)\n",
    "    \n",
    "    distractor_possible_colors = [color for color in range(len(colors)) if color not in goal_colors]\n",
    "    distractor_colors = [random.sample(distractor_possible_colors, distractor_length) for k in range(num_distractor)]\n",
    "    distractor_roots  = random.choices(range(goal_length - 1), k=num_distractor)\n",
    "    keys, locks, first_key, agent_xy = sampling_pairs(goal_length - 1 + distractor_length * num_distractor, n)\n",
    "\n",
    "    # create the goal path\n",
    "    for i in range(1, goal_length):\n",
    "        if i == goal_length - 1: color = goal_color  # the final key is white\n",
    "        else: color = colors[goal_colors[i]]\n",
    "        \n",
    "        banner = 'placed a key with color {} on position {}, corresponding lock at {} with color {}'\n",
    "        if verbose: print(banner.format(color, keys[i-1], locks[i-1], colors[goal_colors[i-1]]))\n",
    "        world[ keys[i-1][0],  keys[i-1][1]] = np.array(color)\n",
    "        world[locks[i-1][0], locks[i-1][1]] = np.array(colors[goal_colors[i-1]])\n",
    "\n",
    "    # keys[0] is an orphand key, so skip it\n",
    "    world[first_key[0], first_key[1]] = np.array(colors[goal_colors[0]])\n",
    "    banner = 'placed the first key with color {} on position {}'\n",
    "    if verbose: print(banner.format(goal_colors[0], first_key))\n",
    "\n",
    "    # place distractors\n",
    "    for i, (distractor_color, root) in enumerate(zip(distractor_colors, distractor_roots)):\n",
    "        key_distractor = keys[goal_length-1 + i*distractor_length: goal_length-1 + (i+1)*distractor_length]\n",
    "        color_lock = colors[goal_colors[root]]\n",
    "        color_key = colors[distractor_color[0]]\n",
    "        world[key_distractor[0][0], key_distractor[0][1] + 1] = np.array(color_lock)\n",
    "        world[key_distractor[0][0], key_distractor[0][1]] = np.array(color_key)\n",
    "        for k, key in enumerate(key_distractor[1:]):\n",
    "            color_lock = colors[distractor_color[k-1]]\n",
    "            color_key = colors[distractor_color[k]]\n",
    "            world[key[0], key[1]] = np.array(color_key)\n",
    "            world[key[0], key[1]+1] = np.array(color_lock)\n",
    "\n",
    "    # place the agent\n",
    "    world[agent_xy[0], agent_xy[1]] = np.array(agent_color)\n",
    "    return world, keys, locks, first_key, agent_xy\n",
    "\n",
    "def update_color(world, previous_agent_loc, new_agent_loc):\n",
    "        world[previous_agent_loc[0], previous_agent_loc[1]] = grid_color\n",
    "        world[new_agent_loc[0], new_agent_loc[1]] = agent_color\n",
    "\n",
    "def is_empty(room):\n",
    "    return np.array_equal(room, grid_color) or np.array_equal(room, agent_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxWorld(gym.Env):\n",
    "    def __init__(self, n, goal_length, num_distractor, distractor_length, max_steps=2**10):\n",
    "        self.goal_length = goal_length\n",
    "        self.num_distractor = num_distractor\n",
    "        self.distractor_length = distractor_length\n",
    "        self.n = n\n",
    "        self.pairs = goal_length - 1 + distractor_length * num_distractor\n",
    "\n",
    "        self.step_cost  = 1e-1\n",
    "        self.reward_gem = 10\n",
    "        self.reward_key = 0\n",
    "\n",
    "        self.viewer = None\n",
    "        self.max_steps = max_steps\n",
    "        self.action_space = Discrete(len(action_space))\n",
    "        self.observation_space = Box(low=0, high=255, shape=(n, n, 3), dtype=np.uint8)\n",
    "\n",
    "        self.owned_key = grid_color\n",
    "\n",
    "        self.np_random_seed = None\n",
    "        self.reset()\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random_seed = seed\n",
    "        return [seed]\n",
    "\n",
    "    def save(self):\n",
    "        np.save('box-world_{}.npy'.format(str(uuid.uuid4())[:8]))\n",
    "\n",
    "    def step(self, action, verbose=False):\n",
    "        self.num_env_steps += 1\n",
    "\n",
    "        change = action_space[action]\n",
    "        new_position = self.agent_xy + change\n",
    "        current_position = self.agent_xy.copy()\n",
    "\n",
    "        reward = -self.step_cost\n",
    "        terminal = self.num_env_steps == self.max_steps\n",
    "\n",
    "        if np.any(new_position < 0) or np.any(new_position >= self.n):\n",
    "            possible_move = False\n",
    "        elif np.array_equal(new_position, [0, 0]):\n",
    "            possible_move = False\n",
    "        elif is_empty(self.world[new_position[0], new_position[1]]):\n",
    "            # no key, no lock\n",
    "            possible_move = True\n",
    "        elif new_position[1] == 0 or is_empty(self.world[new_position[0], new_position[1]-1]):\n",
    "            # it's a key\n",
    "            if is_empty(self.world[new_position[0], new_position[1]+1]):\n",
    "                # key is not locked\n",
    "                possible_move = True\n",
    "                self.owned_key = self.world[new_position[0], new_position[1]].copy()\n",
    "                self.world[0,0] = self.owned_key\n",
    "                if np.array_equal(self.world[new_position[0], new_position[1]], goal_color):\n",
    "                    # goal reached\n",
    "                    reward += self.reward_gem\n",
    "                    terminal = True\n",
    "                else:\n",
    "                    reward += self.reward_key\n",
    "            else:\n",
    "                possible_move = False\n",
    "        else:\n",
    "            # it's a lock\n",
    "            if np.array_equal(self.world[new_position[0], new_position[1]], self.owned_key):\n",
    "                # the lock matches the key\n",
    "                possible_move = True\n",
    "            else:\n",
    "                possible_move = False\n",
    "                banner = 'lock color is {}, but owned key is {}'\n",
    "                if verbose: print(banner.format(self.world[new_position[0], new_position[1]], self.owned_key))\n",
    "\n",
    "        if possible_move:\n",
    "            self.agent_xy = new_position\n",
    "            update_color(self.world, previous_agent_loc=current_position, new_agent_loc=new_position)\n",
    "\n",
    "        metadata = {}\n",
    "        return self.world, reward, terminal, metadata\n",
    "\n",
    "    def reset(self):\n",
    "        args = generate(n=self.n, goal_length=self.goal_length,\n",
    "                        num_distractor=self.num_distractor,\n",
    "                        distractor_length=self.distractor_length,\n",
    "                        seed=self.np_random_seed)\n",
    "                \n",
    "        self.world, self.keys, self.locks, self.first_key, self.agent_xy = args\n",
    "\n",
    "        self.num_env_steps = 0\n",
    "        return self.world\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        img = self.world.astype(np.uint8)\n",
    "        if mode == 'human':\n",
    "            mp.imshow(img, vmin=0, vmax=255, interpolation='none')\n",
    "            mp.show()\n",
    "        else: return img\n",
    "        \n",
    "    def extract_objects(self, feature_maps):\n",
    "        objects = [list(self.agent_xy)] + self.keys + self.locks\n",
    "        return th.stack([feature_maps[...,x,y] for x,y in objects], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute only if run as a script\n",
    "env = BoxWorld(n=12, goal_length=3, num_distractor=2, distractor_length=1)\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 12, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(state.shape)\n",
    "mp.figure(figsize=(15,15))\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The input observation is first processed through two convolutional layers with 12 and 24 kernels, 2 × 2 kernel sizes and a stride of 1, followed by a rectified linear unit (ReLU) activation function.\n",
    "- The output is tagged with two extra channels indicating the spatial position (x and y) of each cell in the feature map using evenly spaced values between −1 and 1. \n",
    "- This is then passed to the relational module (described above) consisting of a variable number of stacked MHDPA blocks, using shared weights. \n",
    "- The output of the relational module is aggregated using feature-wise max-pooling across space (i.e., pooling a n × n × k tensor to a k-dimensional vector)\n",
    "- This is then finally passed to a small MLP to produce policy logits (normalized and used as multinomial distribution from which the action was sampled) and a baseline scalar V.\n",
    "\n",
    "The baseline control agent replaces the MHDPA blocks with a variable number of residual convolution blocks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../graphics/MHDPA.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Entities\n",
    "When dealing with unstructured inputs – e.g. RGB pixels – we need a mechanism to represent the\n",
    "relevant entities.\n",
    "\n",
    "We decide to make a minimal assumption that entities are things located in a particular point in space. We use a convolutional neural network (CNN) to parse pixel inputs into k feature maps of size n×n, where k is the number of output channels of the CNN. \n",
    "\n",
    "We then concatenate x and y coordinates to each k-dimensional pixel feature-vector to indicate the pixel’s position in the map. We treat the resulting n 2 pixel-feature vectors as the set of entities by compiling them into a \n",
    "n^2 × k matrix E. This provides an efficient and flexible way to learn representations of the relevant entities, while being agnostic to what may constitute an entity for the particular problem at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multihead Dot-Product Attention\n",
    "We start by assuming that we already have a set of entities for which interactions must be computed. We consider **multi-head dot-product attention (MHDPA)**, or *self-attention* [[2]](https://arxiv.org/pdf/1706.03762.pdf), as the operation that computes interactions between these entities.\n",
    "\n",
    "For N entities, MHDPA projects each entity i’s state vector into *query, key, and value* vector representations, respectively, whose activities are subsequently normalized to have zero mean and unit variance using the method from [[3]](https://arxiv.org/pdf/1607.06450.pdf). \n",
    "\n",
    "\n",
    "Each query is compared to all entities’ keys via a dot-product, to compute unnormalized saliencies. These are normalized into weights and put through a softmax layer. For each entity, the cumulative interactions are computed by the weighted mixture of all entities’ value vectors. This can be compactly computed using matrix multiplications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 4], [1, 2], [8, 9], [5, 0]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = env.keys\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 5], [1, 3], [8, 10], [5, 1]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locks = env.locks\n",
    "locks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 1]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = [list(env.agent_xy)]\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 objects: [[7, 1], [5, 4], [1, 2], [8, 9], [5, 0], [5, 5], [1, 3], [8, 10], [5, 1]]\n"
     ]
    }
   ],
   "source": [
    "objects = agent + keys + locks\n",
    "print(len(objects),'objects:',objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_objects(xys, feature_maps):\n",
    "    return th.stack([feature_maps[...,x,y] for x,y in xys], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vex = extract_objects(objects, th.randn(1,32,12,12))\n",
    "vex.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relational Module\n",
    "The output of the relational module is aggregated using feature-wise max-pooling across space (i.e., pooling a n × n × k tensor to a k-dimensional vector), and finally passed to a small MLP to produce policy logits (normalized and\n",
    "used as multinomial distribution from which the action was sampled) and a baseline scalar V .\n",
    "Our baseline control agent replaces the MHDPA blocks with a variable number of resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.transformer import MultiheadAttention\n",
    "\n",
    "class RelationalModule(th.nn.Module):\n",
    "    def __init__(self, ch=2048, nhead=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_atntn = MultiheadAttention(24, nhead)\n",
    "        self.layer_norm = th.nn.LayerNorm(ch)\n",
    "        self.dropout = th.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, objects, feature_maps=None):\n",
    "        if not isinstance(objects, list): vex = objects\n",
    "        else: vex = extract_objects(objects, feature_maps)\n",
    "                \n",
    "        _= self.self_atntn(vex,vex,vex)[0]\n",
    "        _= vex + self.dropout(_)\n",
    "        _= self.layer_norm(_)\n",
    "        return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RRLModule(th.nn.Module):\n",
    "    def __init__(self, h1=[12,24], h2=256, actions=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = th.nn.Sequential(\n",
    "        th.nn.Conv2d(3, h1[0], kernel_size=2, stride=1, padding=1), th.nn.ReLU(),\n",
    "        th.nn.Conv2d(h1[0],h1[1], kernel_size=2, stride=1, padding=1), th.nn.ReLU())\n",
    "        nfeats = self.conv1.forward(th.Tensor(1,3,12,12)).size(1)\n",
    "\n",
    "        self.relm = RelationalModule(nfeats)\n",
    "        \n",
    "        self.conv2 = th.nn.Sequential(\n",
    "        th.nn.Linear(nfeats, h2), th.nn.ReLU(),\n",
    "        th.nn.Linear(    h2, h2), th.nn.ReLU(),\n",
    "        th.nn.Linear(    h2, h2), th.nn.ReLU(),\n",
    "        th.nn.Linear(    h2, h2), th.nn.ReLU())\n",
    "        \n",
    "        self.V, self.Pi = th.nn.Linear(h2,1), th.nn.Linear(h2, actions)\n",
    "        \n",
    "    def feature_maps(self, x):\n",
    "        _= self.conv1(x)\n",
    "        return _\n",
    "    \n",
    "    def __call__(self,x,objects):\n",
    "        _= self.feature_maps(x)\n",
    "        _= self.relm(objects,_)\n",
    "        _= th.max(_,dim=1)[0]\n",
    "        _= self.conv2(_)\n",
    "        \n",
    "        v,pi = self.V(_),self.Pi(_)\n",
    "        return v,pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrl_module = RRLModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "v,pi = rrl_module(th.randn(1,3,12,12),objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 12, 12])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inp = th.from_numpy(state.swapaxes(0,1).swapaxes(0,-1)).float().unsqueeze(0)\n",
    "test_inp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0332]], grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.0740, -0.0388, -0.0677, -0.0252]], grad_fn=<AddmmBackward>))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out = rrl_module(test_inp, objects)\n",
    "test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stochastic_policy = lambda:np.random.randint(0,len(action_space))\n",
    "states, actions, rewards, sprimes, terminals = [],[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2466ace5b4b4d598497ecb1a5b435ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "episodes = 2**5\n",
    "for _ in tqdm.tqdm_notebook(range(episodes)):\n",
    "    state = env.reset()\n",
    "    for _ in range(env.max_steps):\n",
    "        states.append(state)\n",
    "        action = stochastic_policy()\n",
    "        actions.append(action)\n",
    "        sprime,reward,terminal,_ = env.step(action)\n",
    "        sprimes.append(sprime)\n",
    "        rewards.append(reward)\n",
    "        terminals.append(int(terminal))\n",
    "        if terminal: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30959, 12, 12, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = np.asarray(states)\n",
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30959, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.asarray(actions).reshape(-1,1)\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30959, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = np.asarray(rewards).reshape(-1,1)\n",
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30959, 12, 12, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_= np.asarray(sprimes)\n",
    "S_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30959, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = np.asarray(terminals).reshape(-1,1)\n",
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents import Agent\n",
    "from rl.memory.short_term import ShortTerm\n",
    "from rl.policy.categorical import Categorical\n",
    "from rl.util import compute_returns, estimate_advantage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proximal Policy Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO(Agent):\n",
    "    def __init__(self, model, optim, lossfn, memory, policy, device=th.device('cpu'), *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.lossfn = lossfn\n",
    "        self.memory = memory\n",
    "        self.policy = policy\n",
    "\n",
    "    def memorize(self, reward, terminal):\n",
    "        self.memory.retain(value=self.state_value.squeeze(),\n",
    "                           logprob=self.logprob,\n",
    "                           reward=reward,\n",
    "                           terminal=terminal)\n",
    "\n",
    "    def __call__(self, state, objects):\n",
    "        self.state_value, logits = self.model(state, objects)\n",
    "        self.action, self.logprob, self.entropy = self.policy(logits)\n",
    "        return self.state_value, self.action\n",
    "\n",
    "    def update(self, sprime, oprime, clip_param=1e-2, *args, **kwargs):\n",
    "        values, logprobs  = th.tensor(self.memory.values), th.tensor(self.memory.logprobs).float()\n",
    "        rewards,terminals = self.memory.rewards, self.memory.terminals\n",
    "\n",
    "        state_value,_ = self.model(sprime, oprime)\n",
    "        \n",
    "        values = values.view(-1,1)\n",
    "        state_value = state_value.view(-1,1)\n",
    "      \n",
    "        returns = estimate_advantage(state_value, values, rewards, terminals)\n",
    "        returns = th.cat(returns).detach()\n",
    "        advantage = returns - values\n",
    "        \n",
    "        ratio = (self.logprob - logprobs).exp()\n",
    "        surr1 = ratio * advantage\n",
    "        surr2 = th.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantage\n",
    "\n",
    "        ploss = -th.min(surr1, surr2).mean()\n",
    "        vloss = (returns - values).pow(2).mean()\n",
    "\n",
    "        loss = vloss + ploss\n",
    "\n",
    "        self.optim.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "\n",
    "        self.memory.wipe()\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = RRLModule()\n",
    "optim  = th.optim.Adam(model.parameters(), amsgrad=True, lr=1e-3)\n",
    "lossfn = th.nn.MSELoss()\n",
    "memory = ShortTerm()\n",
    "policy = Categorical()\n",
    "\n",
    "agent = PPO(model, optim, lossfn, memory, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4207e9926d47a2879e4f7db72c851a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=256), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preprocess = lambda x:th.from_numpy(x.swapaxes(0,1).swapaxes(0,-1)).float().unsqueeze(0)\n",
    "losses,returns = [],[]\n",
    "episodes = 2**8\n",
    "for episode in tqdm.tqdm_notebook(range(episodes)):\n",
    "    state = env.reset()\n",
    "    cummulative = 0\n",
    "    for _ in range(env.max_steps):\n",
    "        input = preprocess(state)\n",
    "        \n",
    "        objects= env.extract_objects(agent.model.feature_maps(input))\n",
    "        state_value, action = agent(input, objects)\n",
    "        sprime,reward,terminal,_ = env.step(action)\n",
    "        oprime = env.extract_objects(agent.model.feature_maps(preprocess(sprime)))\n",
    "        \n",
    "        agent.memory.retain(reward, terminal)\n",
    "        cummulative += reward\n",
    "        if terminal: break\n",
    "            \n",
    "    returns.append(cummulative)\n",
    "    loss = agent.update(preprocess(sprime), oprime)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/4AAAJiCAYAAAB+TxlBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xm8ZGddJ/7Pt293k50lCSgJIQGCrMqODoIwisLMKC4oKLIoI8OPwWFwBVRgUEQBQVQcBEUQRXBcmKgoPzBsLkACAWQRE0J2lmxk7Sx97zN/nLrNudX33q5OV/Vyzvv9et1Xqs45VfXcqrrQn/P9Ps+p1loAAACAYdpyoAcAAAAALI7gDwAAAAMm+AMAAMCACf4AAAAwYII/AAAADJjgDwAAAAMm+ANAkqp6U1X9zR6O+ZuqetN+GtIgVNVjqqpV1VF78ZhnVtVlixwX+8f++Cyr6ver6u8X+RoAhzrBH+AQMgmnbfJzc1WdW1WvrKojJ/tP7u1vVXVlVX2gqr5t6nlOqKrXV9VFVXVTVV1cVW+oqhP38PrTz39jVf17Vf3MnH/Pl1XVOVPbTpy85t9Mbf+Oyfa7znMM+6qqPlFVO6vq7gdwDE+rqmv3cMybpj7T3X72cRinJ/n6JNftxWPenORe+/i6e1RV95j8jvdZ9GvdElX1wKp6++TvdEdVfbaqnltV1TvmHht8bo/sHfOYDY45eZPXPmyT78TT9uLX2C+fJQCbE/wBDj3vSRek7pLkF5M8K8krp455zOSYb0tyVZJ3VtUpSTL575lJ7pPkqUnuluRHk9w7yRmbhYF1nv/uSV6W5GVV9YR9+aWmvDfJXadORDwqyYVJHl5VS1PbL2itff6WvFBVbe0HqXmoqockuX2SP0ry9Hk+9wI8J91nufpzfZL/ObVtN1W1fZYnb63d1Fr7Umtt5hMIrbUdrbWvzHr8gD04ySVJnpTu7/OlSX4lyXPXOfaRWfuZ/fM6x9x16pgLZxjDk6ce8/VJ3j7rL+CzBDg4CP4Ah54bJ0HqwtbaW5P8SZLvnTrm8skxn0zyzCRHJPnOyb7XJllJ8h2ttX9orV3QWntvku+YbH/tDGNYff7zW2t/mOQTSR6wurOqtlTVL1XVhZOugH+tqsf19j+5qq6vqnv0tr1scvxtk/xTkpvThfpVj0oXpK/pv9Zk++m95zmpqv6qqq6Z/Pxl/wRCVb24qj41qYZ/PsmNSY6c/gWr6ohJNfzaqvpyVb1ghvdl1dOTvDXJHyZ5SlVtnXruI6vqj3rP/fyamkZQVdur6tcn1d7rq+qMqvqu3v5HTqqv315VH54cc2ZVPWB1/+T1j+xVal88PdDW2lWTz/JLrbUvJWlJprelqj5UVa+Z/FyW5B8m239+8n5eN/n8/ndVHdMb55pW/5q0fk+2f2byHrynqk7qPWZNe3hV/drkd3tKVX2hqq6uqj+ffFdWj9lWVb9TVVdV1eVV9fKq+oPaxxbwqvrJ6jprbqquu+Wp6+w/Z/I9v7Sq/q637/5V9b7ed/GsqvrWWV+7tfa61tpzW2vvb62d21r74yR/kOQH1jn88v5n1lq7aZ1jvjJ1zPIMw/jq1GO+1FrbMfn9Vj/LH6iqs6vqhqp69x4+y1Mm3/UrJ9+Zz1TV96/znu2YfI6/X1VH9/ZvnXwHvzrZ/4pM/Xu2uv/9+YXJd2VHVX2yqn6ot7+q6per6oLJ53ZJVf3+DO8FwCFL8Ac49O1Ism0P+5NkW1XdLl21/rWttev7B03u/26Sx/YD1WYm/4B+WJJ7Jvlwb9dzkvxskp9Pct8kf5XkL6vqfpPXekuSdyR56yTgPjLJzyR5SmvtytbadUk+kt2D//uSvH91+yRMPjhdh0CqakuS/5vkDpNjHpXkjkneUbWmqn9Kkh9J8oNJvinJDev8eq9M8uh0Ievbk9w/ySNmeE+OTPLEJH+c5B/Tvf//Zeqw30jXjfF9Sf7jZAwPnzrmDyfH/Ei67ow3J/nrqvqmqeNeluR56U6GXJ7kTya/6z+nq9xfn69Vaqc7Q/bWj0+e7z8k+YnJtp1Jnp2uIv2UyZh/Yw/Pc3S6qvVT0v3eX5fkt/fwmG9I8t2Tn/+U5FuSvLi3/xfSve9PSfKwyWs8fs+/0saq6ofTvWcvT/cZvC7JG6vq0ZP9D0v3u/5CklPTfV/e03uKP0vyhSQPSvf9+ZV0J5r2xTFJrlxn+zurO4n0weqdZJvyqUnIfXdVTX/fbqmj0/2dPznd+35Ukv+zyfGvT1Lp/pbum+7v/uokmZwweleSr6T7u/7BdH8fr+s9/gWT1/rxyesdk90/51ek+7v5b+mmGfxGkjdX1XdM9v9Ikv+e7jt8apLHJfnoXv3WAIea1pofP378+DlEfpK8Kcnf9O4/JMllSd4+uX9yuortgyb3j0z3j+ad6f6R/dDJ/u/b4Pm/b7L/IRvsX33+65Ncm+Smyf1XTx13cZIXTm17X5I/7t2/dZLz0gWBC5P8+tTxv5zkC73XvTFd58IzkvzdZPtjJq9/4uT+o5MsJzm59zx3ydc6HJIuLN6c5A4bvbfpwsuNSZ7U239Ukq8medMePqOnJflU7/5Lpj6zoybv2xN7245MF+beNLl/18mYT5p67nck+d3J7UdOfvfv6u1/2NT78bQk1+7ld+zaJE9bZ/uHkpwxw+O/N8k1vfurn9FRk/vPnNy/c++Yp0895plJLuvd/7V0nR5HTn0/+u/zFUn+Z+/+UrrQ/febjPUek7HcZ4P9H119v3vb3pbkPZPbP5Lu7++IdR5b6U4oPWFv3v89vLffPPnu/Ofetq9Pd4LnoenC8ssm353H9465d7qQ+4B0J21+P93/Jjx0k9c6bPLe7Jh8J/o/d5/6LB/Ye9ypk23fusFn+e9Jfn6D1/zJyft5+NT3ZyXJnSb3L0/y01Of83mrn3OS20zeowdPPffrkvzl5PYLkvxrkqV5fTZ+/Pjxc7D/qPgDHHoeM2mPviHJvyT5QLp/MPd9oLpF3a5JVyF9WmvtX+c4hh9Jcr90leofSvLDVfUrya6q3R3Ttev3/WN6i3y11q5Kt8bAT6T7x/4vTh1/epKTq1tz4FHpQuf16U4gfGt17fOPSnJOa+2iyWPumeSS1tp5vdc5N9086f4CYxe11r68ye931yTb072/q89zbbqwsCf/Nclbevffku4zu2Pvubel62hYfe7rknyq95gHpAuOq63w104+z/88eXzfJ3u3L5n89/YzjPOWOHN6Q1V9Z1WdXt0Ckdekm+Jw1KS7ZCNXt9bO792/ZPKYIzZ5zLmT96n/mNtPxnCHJLfN2vd0eb3x7qV7ZPPv8TvTVafPq6q3VNWPTjo+0lprSV6d5I8nFfbnV9Wpt3Qg1S1AeFqSX22t/e3q9tbaF1trv9la+3Br7YzW2vPTncT6ud4xn26tvaG19rHW2j+31v5ruv/d+OkZXvp/pPtb7/98obf/piQf673W2en+njda0O83k/xKVf1TVb1ktQto4p5JzmqTqQQT/5jub+Gek8/5dln7d7mc5Ize8fdN9/f13qm/nR/L1/523jZ5ni9Ut6jpD1TVZl1TAIc8wR/g0POBdP/4/oYkh7XWvr/tvnjWj6QL5ce31k5o3dzgJDknXTVuo3+U32uy/5wN9q+6qLV2Tmvts621/5PuH/M/X1WH7eFx0wu8PSJdhf726Vp2+/4lXdX9kZOf9yVJa+3f053QeNBk++mZTf+192aF+ZlVt2bBw5L8anUr+u9M8tl0Vckf24un2pJuvA/O2sB1z3Qtzn03926v/o6L+v/3Ne/bJMj+dZKz0k2JeGC6Cm/SnTjZyM1T92cZ93qPOVD/jmlJ0lr7arq/syelOxHxwnQna24/2f/8dFME3pnuu/7pqnrS3r5YVd033ff8ja21F8/wkA+nq7zv6zFJ8sXJ33r/Z/qzmFlr7XfTBfC3pPvfm49U1fNmeeiML7H6nXhM1v7t3DvdSdDVk4F3SzdF5fokv5XkwzP87xfAIUvwBzj0XD/5x/f5m/wD/KLW2udba5f3N07uvyvJs6arq5P7/z1dG/0Vezmm5SRbk2xvrV2dLgQ9bOqYb03ymd7rPTTJL6WbXnBJkjdMjXW1o2F1rv77ervfn25e7gOzNvh/Nskdq3dlgqq6S7oOhM9kdp9PFzS/ufc8R6YLcZt5erpA9U1ZGzpenOTHJ3PvV5/7wb3nPmLquc9KV+X8unVC18V78XvclO6kw6I8JF1x+6dbax+anJTZ9JKQizDp3rgya9/TLem+H/vi37KH73Fr7ebW2rtbaz+fycm2dKFzdf/nWmuvbq09Nt1CnHt1lYeq+sZ03/E3tdZmCchJ95374hyOmcX2dOsXJEmq6m5Jjkv3t7iu1i0o+rrW2uPTXangGZNdn01y/6o6vHf4t6YL/f/W+5z7f5dL6X3u6bpydqabGjD9t3NBbww7Wmuntdaek276w/3TfZ8BBmnrng8BYGCenW7ht/dU1S8mOTtdBe6l6cLms2d4jmOr6uvS/f/IfdMt5vfeSehPusW1XlJVZ6ebJ/2j6RZxW11x/qh0i9+9rrX211X1b0nOqqqnt9b+oPc67023+NetsvbyZO9Pt+Da0uSYVe9J1/r+J1X1nMm2307XijxrZ0Baa9dW1R8k+fWqujRfq+ZuGKInrcJPSfLS1tqnpvZdPnn8o1prp1fVGyfPfVm68PWL+VqVP621f6+qP0nypqr66cn4b5euw+Hc1tpfzvirnJfksMlidGelO2l0/eYP2StnJ7lVVT07yd+mC2nPmuPz743fSvILVfWFJJ9LN/3l2MxWKf6GmrryQrpw/4p0i8J9PN337LvTLTj3mCSpbjX6O6ZrR78y3ZUzDkvy2aq6dbp1CP4i3edwQroFCd+TGU3a4P8hyd8kedXkby7pTrZ8eXLM09PNu//EZN/3pps+85O95/mZdO/JZyfj+7Ek35XdF51cz216r7vqmt60i5uS/O7k7+3mdH9vZ7bWPrjB7/Q76aYsnJ1uesaj87UTKW9OdzLwTVX1y+lOorw2yZ+21lYvPfiadJ/zuelOzDwn3d/G6htzRVW9JslrJn+T/5Sum+g/JNnRWntjVf1EupMDZ6TrYnny5Pe4RZcEBTgUCP4AI9Na+3xVPShdEH1Lujb7S9O1Iz+hN19+M6uXSFtOF1zfmW5l81W/lW6175enW2H/c0l+oLW2Gk5ek+4f2j83GdPZk+Dwmqp6f2ttdarBe5P8ryT/NBVY3zd5/k/3pzm01tpkRfPfytdOCLwnyU9O5lzvjZ9Jt+jeX6VrB/7trHPZv57vThdU/mJ6R2vti1X1T+nm/5/ee+7T0oW2V6d7n/pXF/ixdO/py9NV0a9IN4e9f6JjU621f66q1yX503Qh+H9l7Ur4+6S19pGq+tl0i6W9PMkH063w/sebPnAxXpru/X9Luu/lG9J9L2dp3/7zdbad2lp7W1Udn+6qCb+TLsA/vbX27skxV6YLni+ZvM456a5Mccaki+P2k/HcId2899PSvT9Jkqr6UpJ3tNZWp0dMe2K6UPuUyc+qG3u/V6X7TO+cLnh/LsmPttbe1jv+sHTTce6Y7rv8qXSLQr47e/aWdbb9UrorFCTdtJvfSPcdOyHdSZDNpjNsS/K/J8deneTdSX4qSVprV1d3ycpXpwvl16f7+3tu7/G/mu5zfnO6Rf/+MN3nd8feMT+X7mTdC9It7vnVdCe+fm2y/6vp/gZ/M93JvE8nedxedtMAHFJq7/8dBADMU1XdKsn5SV7RWtvTpfCYwWRaxaeT/G1r7WcP9HimTRbBvCzdyba/OtDjuSWq6plJfqW1dtyBHgsAm1PxB4D9rKrun26hvo/ka9dBPzrJ2w/kuA5lVXXXdFMhPphuasiz0i1et17F+mDw6CSnH6qhH4BDi+APAAfGT6W7MsPOJB9P8ogZp1mwvpZu4bxXpWt//3SSR7fWPrnpow6Q1tpfZJ1pIQCwCFr9AQAAYMBczg8AAAAGTPAHAACAARv1HP/jjjuunXzyyQd6GAAAALBXPvrRj17WWjt+lmNHHfxPPvnknHnmmQd6GAAAALBXqur8WY/V6g8AAAADJvgDAADAgAn+AAAAMGCCPwAAAAyY4A8AAAADJvgDAADAgAn+AAAAMGCCPwAAAAyY4A8AAAADJvgDAADAgAn+AAAAMGCCPwAAAAyY4A8AAAADJvgDAADAgAn+AAAAMGCCPwAAAAyY4A8AAAADJvgDAADAgAn+AAAAMGCCPwAAAAyY4A8AAAADJviPTGstH7zoovz15z+fG3fuPNDDAQAAYMG2HugBsH/92xVX5OUf+UiSZKW1PO5udzvAIwIAAGCRVPxH5vyrr951+wtXXXUARwIAAMD+IPiPTGtt1+2dKysHcCQAAADsD4L/yKz0gv+y4A8AADB4gv/I9KP+zt5JAAAAAIZJ8B+ZFa3+AAAAoyL4j4w5/gAAAOMi+I9Mv7lf8AcAABg+wX9k+gv6LZvjDwAAMHiC/8io+AMAAIyL4D8y5vgDAACMi+A/Mmsu5yf4AwAADJ7gPzJrLudnjj8AAMDgCf4j02/1X1bxBwAAGDzBf2RWzPEHAAAYFcF/ZLT6AwAAjIvgPzL9qK/VHwAAYPgE/5HpV/xvFvwBAAAGT/AfmX7wX9bqDwAAMHiC/8isTK3q34R/AACAQRP8R2Y65qv6AwAADJvgPzIrU0HfJf0AAACGTfAfGcEfAABgXAT/kZme06/VHwAAYNgE/5GZru/fvLx8QMYBAADA/iH4j8x0q7+KPwAAwLAJ/iMz3epvjj8AAMCwCf4jM13fF/wBAACGTfAfmeWpoK/VHwAAYNgE/5GZjvk3q/gDAAAMmuA/Mrtdzk/wBwAAGDTBf2SmY/5Orf4AAACDJviPzPTl/CzuBwAAMGyC/8gI/gAAAOMi+I/M9Bx/wR8AAGDYBP+Rma74u5wfAADAsAn+I6PVHwAAYFwE/5GZru8L/gAAAMMm+I+Mij8AAMC4CP4js1vwN8cfAABg0AT/kZmO+csq/gAAAIMm+I+MVn8AAIBxEfxHRqs/AADAuAj+I9NU/AEAAEZF8B+Z6Zhvjj8AAMCwCf4jM93qf7PgDwAAMGiC/8hMt/ovm+MPAAAwaIL/yFjVHwAAYFwE/5ER/AEAAMZF8B+Z6cZ+rf4AAADDJviPzG6L+y0vH6CRAAAAsD8I/iOj4g8AADAugv/ImOMPAAAwLoL/yAj+AAAA4yL4j0ybCv5a/QEAAIZN8B+Z3Rb3U/EHAAAYNMF/ZKZj/rLgDwAAMGiC/8hMt/rv1OoPAAAwaAdV8K+qx1TV56rqnKp63jr7H1FVH6uqnVX1+Kl9y1X18cnPaftv1IcWi/sBAACMy9YDPYBVVbWU5LVJHp3koiRnVNVprbXP9A67IMnTkvzMOk+xo7V2v4UP9BA3Hfwt7gcAADBsB03wT/KQJOe01s5Nkqp6W5LHJdkV/Ftr5032KVPfQtMx/+bl5QMyDgAAAPaPg6nV/4QkF/buXzTZNqvDqurMqvpQVX3vfIc2HCr+AAAA43IwVfz31Z1baxdX1V2SnF5V/9pa+/z0QVX1jCTPSJKTTjppf4/xgDPHHwAAYFwOpor/xUnu1Lt/4mTbTFprF0/+e26S9yW5/wbHvb619qDW2oOOP/74Wz7aQ9R0fV/wBwAAGLaDKfifkeTUqjqlqrYneWKSmVbnr6rbVtWtJrePS/Kw9NYG4GtU/AEAAMbloAn+rbWdSZ6d5F1JPpvkz1prn66ql1TV9yRJVT24qi5K8oNJfq+qPj15+D2TnFlVn0jy3iS/NnU1ACbM8QcAABiXg2qOf2vtnUneObXthb3bZ6SbAjD9uH9Oct+FD3AA2joV/9ZaquoAjQgAAIBFOmgq/izedOhfpeoPAAAwXIL/iEy3+a9aNs8fAABgsAT/Edmorm+BPwAAgOES/Edko4r/Tq3+AAAAgyX4j4hWfwAAgPER/Edkw4q/4A8AADBYgv+IbLSqv1Z/AACA4RL8R2Sjur6KPwAAwHAJ/iOi1R8AAGB8BP8R2bDVX/AHAAAYLMF/RDZc1d8cfwAAgMES/EdEqz8AAMD4CP4jslFdX/AHAAAYLsF/RMzxBwAAGB/Bf0Q2msu/0xx/AACAwRL8R2SjeL+s4g8AADBYgv+IaPUHAAAYH8F/RDZc1V+rPwAAwGAJ/iPicn4AAADjI/iPiOAPAAAwPoL/iGy4uJ9WfwAAgMES/Edko4r/zcvL+3kkAAAA7C+C/4hsFPxV/AEAAIZL8B+RjeK9Of4AAADDJfiPiMX9AAAAxkfwHxGt/gAAAOMj+I9IU/EHAAAYHcF/RDaK94I/AADAcAn+I7LhHH+t/gAAAIMl+I+IVn8AAIDxEfxHZMPF/QR/AACAwRL8R0SrPwAAwPgI/iOyUbzX6g8AADBcgv+I9Cv+W7d87aMX/AEAAIZL8B+RfvDfJvgDAACMguA/Iv1W/21LS7tuL5vjDwAAMFiC/4j0K/7bVfwBAABGQfAfkdZv9e9V/AV/AACA4RL8R0TFHwAAYHwE/xHpx/vt/Yq/Of4AAACDJfiPSNtgVf9lFX8AAIDBEvxHZMUcfwAAgNER/Edkwzn+Wv0BAAAGS/AfkX68V/EHAAAYB8F/RKzqDwAAMD6C/4iY4w8AADA+gv+IrGn176/qb44/AADAYAn+I9Kv+G/dsiVVlaS7zN+K8A8AADBIgv+I9MP9lqpsNc8fAABg8AT/EWm94F9JliYV/0TwBwAAGCrBf0SmK/7bVPwBAAAGT/AfkengvyT4AwAADJ7gPyL95fsqyVat/gAAAIMn+I/IZov7uaQfAADAMAn+I6LVHwAAYHwE/xFZ0+pvcT8AAIBREPxHZE3FP1OX89PqDwAAMEiC/4i0Teb4q/gDAAAMk+A/Iv0F/Gp6cT/BHwAAYJAE/xHpN/PvVvHX6g8AADBIgv+I7Nbq35/jr+IPAAAwSIL/iPQX96tkzeX8llX8AQAABknwH5GVTRb3u3l5+UAMCQAAgAUT/Edktzn+vVZ/FX8AAIBhEvxHZLrV3+X8AAAAhk/wH5HpVv8lwR8AAGDwBP8R0eoPAAAwPoL/iKxp9Z9e3E/FHwAAYJAE/xHZbFX/ZcEfAABgkAT/EWkW9wMAABgdwX9E+hX/paos9eb47zTHHwAAYJAE/xGZnuO/Tas/AADA4An+I9KP9pWsuZyfxf0AAACGSfAfkbbZ4n5a/QEAAAZJ8B+R3Vb178/xV/EHAAAYJMF/RKbn+C9Z1R8AAGDwBP8R6Tfzb0nWLO4n+AMAAAyT4D8i03P8l7T6AwAADJ7gPyLLU63+FvcDAAAYPsF/RNa0+k8FfxV/AACAYRL8R0SrPwAAwPgcVMG/qh5TVZ+rqnOq6nnr7H9EVX2sqnZW1eOn9j21qs6e/Dx1/4360LHmcn5Jti0t7bq/U6s/AADAIB00wb+qlpK8Nsljk9wryQ9X1b2mDrsgydOSvHXqsbdL8qIkD03ykCQvqqrbLnrMh5rdLufXq/gvq/gDAAAM0kET/NMF9nNaa+e21m5K8rYkj+sf0Fo7r7X2ySTTKfW7kry7tXZFa+3KJO9O8pj9MehDiTn+AAAA43MwBf8TklzYu3/RZNuiHzsaK1Nz/NcEf63+AAAAg3QwBf/9oqqeUVVnVtWZl1566YEezn61ptU/sbgfAADACBxMwf/iJHfq3T9xsm2uj22tvb619qDW2oOOP/74WzTQQ9X0HP9tWv0BAAAG72AK/mckObWqTqmq7UmemOS0GR/7riTfWVW3nSzq952TbfT0m/mXqrLUC/7LWv0BAAAG6aAJ/q21nUmenS6wfzbJn7XWPl1VL6mq70mSqnpwVV2U5AeT/F5VfXry2CuS/HK6kwdnJHnJZBs9063+W3ut/jcvLx+AEQEAALBoWw/0APpaa+9M8s6pbS/s3T4jXRv/eo99Y5I3LnSAh7jpVv+tKv4AAACDd9BU/Fm81gv3Sy7nBwAAMAqC/4j0o31VWdUfAABgBAT/Edltjr9WfwAAgMET/Eek3+q/ZarV/2YVfwAAgEES/EdkZSr4b+m1+rfW1pwYAAAAYBgE/xGZDv5VlSXt/gAAAIMm+I9IP9av1vr7C/ytCP4AAACDI/iPyHTFv//fJFk2zx8AAGBwBP8RWS/49yv+Wv0BAACGR/AfkTWt/qvB3xx/AACAQRP8R2SPFX+t/gAAAIMj+I9I/3J9qx+8xf0AAACGTfAfkX6wr3UW99sp+AMAAAyO4D8i67b69+f4a/UHAAAYHMF/RPr1/PXm+Gv1BwAAGB7Bf0TWtPpP/rvVqv4AAACDJviPyHqt/v05/oI/AADA8Aj+I7KnVn9z/AEAAIZH8B+J1tqay/mtWlLxBwAAGDTBfyT6kb6qdl3Oz6r+AAAAwyb4j8R68/uTqVX99+uIAAAA2B/2GPyramtVPauq7rg/BsRirLeifzK1uJ+KPwAAwODsMfi31nYmeUWSbYsfDovSZqj4m+MPAAAwPLO2+n8oyQMWORAWa70V/ZOpOf6CPwAAwOBsnfG4NyT5jaq6c5KPJrmuv7O19rF5D4z56rfx91v9Xc4PAABg2GYN/m+d/PdV6+xrSZbmMxwWZcOKv1Z/AACAQZs1+J+y0FGwcDO1+qv4AwAADM5Mwb+1dv6iB8JirVnVX8UfAABgNGZd3C9V9Y1V9UdVdWZVnVFVb66q+yxycMzPykar+vcq/iuCPwAAwODMFPyr6nuSfCzJnZL8XZK/T3JSkrOq6rsXNzzmZc3l/HrbVfwBAACGbdY5/r+S5KWttRf1N1bVSyb7/nreA2O+Nqr4b7GqPwAAwKDN2up/9yRvWWf7W5J8w/yGw6KY4w8AADBOswb/ryR54DrbH5jky/MbDovSj/TVu71mVX/BHwAAYHBmbfV/Q5Lfq6q7JfnnybaHJfmZJK9YxMCYr37Fvx/2l7T6AwAADNrezPG/NslPJ/nlybZLkrwoyW8tYFzM2ZpW/952rf4AAADDtsfgX1Vbktwjyetba6+uqqOTpLV2zaIHx/xsNMd/i+APAAAwaLPM8W9JPp7k65Mu8Av9h55+pF9zOb/+HH+t/gAAAIOzx+BcsLGdAAAgAElEQVTfugvAfy7J8YsfDouy0eX8tvZur6j4AwAADM6sq/r/XJJXVtX9qt8nziFjw8v5WdUfAABg0GZd3O/PkhyW5KNJdlbVjf2drbVj5j0w5mtNq785/gAAAKMxa/B/9kJHwcJt1Orvcn4AAADDNsuq/luTHJnkHa21SxY/JBZhTfDvbXc5PwAAgGGbZXG/nUlekWTb4ofDojRz/AEAAEZp1sX9PpTkgYscCIu10Rz/Jav6AwAADNqsc/zfkG5V/5PSLfB3XX9na+1j8x4Y89Wfv7/h4n7m+AMAAAzOrMH/rZP/vmqdfS3J0nyGw6L0a/n96zH2K/47BX8AAIDBmTX4n7LQUbBwG7b69+b4i/0AAADDM1Pwb62dv+iBsFgu5wcAADBOmy7uV1Vvraqje/efOXX/tlX1gUUOkPnoB/+NWv2t6g8AADA8e1rV/wlJDu/df3mS43v3tyd52LwHxfxtWPHvX85PxR8AAGBw9hT8aw/3OUS0WVr9VfwBAAAGZ0/Bn4Ho1/Jrg+C/IvgDAAAMzizBXxocgA3n+Pdb/QV/AACAwZllVf+XVdX1k9vbk7yoqq6a3D9iMcNi3vqt/v2wv8Wq/gAAAIO2p+D/gSR37d3/5yQnrXMMBzmr+gMAAIzTpsG/tfbI/TQOFmzDVf0FfwAAgEGzuN9I9CP9hnP8tfoDAAAMjuA/Eir+AAAA4yT4j8SGwd+q/gAAAIMm+I/Emlb/jSr+Wv0BAAAGR/AfiVla/VdU/AEAAAZnw1X9q2r6sn0baq1dMJ/hsChrgn9vu1Z/AACAYdvscn7nZW2H+GaW9n0oLFLrhfp+q/8Wi/sBAAAM2mbB/8G923dP8vIkr0vyL5Nt35LkvyX5+cUMjXmaaVV/c/wBAAAGZ8Pg31r76OrtqnpVkue21v68d8jpVfW5JM9J8qeLGyLz0I/0LucHAAAwHrMu7veQJJ9cZ/snkzxwfsNhUda0+ve29+f4W9wPAABgeGYN/ucledY625+V5Py5jYaFmaXVf+fKypoTBAAAABz6Npvj3/fcJH9VVY9J8qHJtocmOTnJ9y9gXMxZP873g39Vpap2Bf6WtR0BAAAAHNpmqvi31v4+yalJ/jLJMZOfv0xy99ba3y1ueMzLygat/okF/gAAAIZs1op/WmsXJXnBAsfCAm3U6p90wX/n5PZya9m2H8cFAADAYs06xz9Vdd+q+p2qemdVff1k2/dW1f0XNzzmpW0W/HsL/Kn4AwAADMtMwb+qvjPJGUlOSPLtSQ6f7LprkhctZmjMUz/O1zoV//WOAwAA4NA3a8X/l5P8VGvt+5Lc1Nv+vnSX+uMgt1mr/xZz/AEAAAZr1uB/nyTvXGf7FUluN7/hsCibtvr3g7/L+QEAAAzKrMH/inRt/tMekOSi+Q2HRdl0VX9z/AEAAAZr1uD/1iSvqKoT013qfWtVfVuSVyb5o0UNjvnZ06r+q1T8AQAAhmXW4P+LSb6Q5PwkRyX5TJLTk/xjkpcuZmjMUz/Ob1bxXxH8AQAABmXrLAe11m5O8qSq+qV07f1bkpzVWjt7kYNjfjZd3K93e6dWfwAAgEHZY/Cvqm1JLkzy7a21Tyc5d+GjYu42bfXvz/FX8QcAABiUPbb6T6r9N2dttziHmDWt/ub4AwAAjMasc/x/O8nzq2qmqQEcfDar+G81xx8AAGCwZg3yD0/ybUkurqpPJbmuv7O19j3zGExVPSbJa5IsJfn91tqvTe2/VbqrCDwwyeVJntBaO6+qTk7y2SSfmxz6odbaM+cxpqFYE/yn9vVPBLicHwAAwLDMGvwvS/IXixxIVS0leW2SRye5KMkZVXVaa+0zvcOenuTK1trdquqJSX49yRMm+z7fWrvfIsd4KGu94K/VHwAAYDxmXdX/xxY9kCQPSXJOa+3cJKmqtyV5XLpLB656XJIXT27/eZLfqekUy7os7gcAADBOs87x3x9OSHf1gFUXTbate0xrbWeSq5IcO9l3SlWdVVXvr6qHL3qwh5p+A/9uwV+rPwAAwGDNvFhfVf1Ykh9OclKS7f19rbW7zHlce+uLSU5qrV1eVQ9M8o6qundr7erpA6vqGUmekSQnnXTSfh7mgbOm1X9qXz/4W9wPAABgWGaq+FfVzyb5jSQfTXJyknck+VSS2yV545zGcnGSO/XunzjZtu4xkysM3DrJ5a21G1trlydJa+2jST6f5O7rvUhr7fWttQe11h50/PHHz2noB7/NWv23mOMPAAAwWLO2+v9Ekme01p6f5OYkvzNZyf83ktx5TmM5I8mpVXVKVW1P8sQkp00dc1qSp05uPz7J6a21VlXHTxYHTFXdJcmpSc6d07gGoR/nzfEHAAAYj1mD/4lJPjK5vSPJMZPbf5rkB+YxkMmc/WcneVe6S/P9WWvt01X1kqpavVzgHyQ5tqrOSfJTSZ432f6IJJ+sqo+nW/Tvma21K+YxrqHoz93frNXfHH8AAIBhmXWO/5eSHJfkgiTnJ/mWJB9PcresLSbvk9baO5O8c2rbC3u3b0jyg+s87i+y4MsNHuo2rfhr9QcAABisWSv+pyfpV91fVVXvTfL2JH+5iIExX83l/AAAAEZp1or/MzI5SdBae11VXZnkYemq7L+3oLExRy7nBwAAME4zBf/W2kp62bG19vZ01X4OEf1V/UurPwAAwGjMFPyr6gGb7W+tfWw+w2FRtPoDAACM06yt/memWx+unxj7CXFpbiNiIfoV/+mFHfoV/xXBHwAAYFBmDf6nTN3fluT+SX4hyfPnOiIWYrNW/y3m+AMAAAzWrHP8z19n8zlVdVWSFyX5u7mOirnr1/Frap85/gAAAMM16+X8NvKFJPebx0BYrH7Fvz+nf/q+4A8AADAssy7ud7vpTUm+PsmLk3xuzmNiAda0+k/tczk/AACA4Zp1jv9lWdstnnT58cIkT5jriFiINa3+LucHAAAwGrMG/0dN3V9JcmmSc1prO+c7JBZhs1X9Le4HAAAwXLMu7vf+RQ+ExVoT/Kcq/lvN8QcAABisWef4P2LWJ2ytfeCWD4dF2exyfv3F/VYEfwAAgEGZtdX/ffnaNPHV1Dh9f3Xb0r4Pi3lrm1T8zfEHAAAYrlkv5/df0q3e/5Qkd5v8PCXJvyX57iTHT35uv4AxMgf9OD8d/M3xBwAAGK5ZK/6/nOQ5rbV397adW1VfSfLy1tr95z805mlZxR8AAGCUZq343yvJRetsvzjJPeY3HBal3+pfU/uWLO4HAAAwWLMG/08neVFVHb66YXL7hZN9HOQ2a/Vf0uoPAAAwWLO2+v9/Sf4mycVV9cnJtvsmWU7ynxcxMOarH+g3C/5W9QcAABiWmYJ/a+2MqrpLkifla639f5Lkra216xY1OOanH+enW/37JwJ2Cv4AAACDMmvFP5OA//oFjoUF2rTVvz/HX6s/AADAoGw6x7+q7lRV957a9qiqOr2qPlJVz1vs8JiXlRlX9dfqDwAAMCx7WtzvVUmevHqnqk5K8tdJbp/ki0leUlU/ubjhMS/9QF9TwX+rVf0BAAAGa0/B/yFJ/rZ3/0npAv/9WmuPS/KCJD+2oLExR/3L+U1/6P0OAMEfAABgWPYU/G+f5Pze/UcmeUdrbefk/mlJTlnAuJizWVv9zfEHAAAYlj0F/68mObZ3/8FJPtS737IXCwRy4GzW6r+k4g8AADBYewr+H07y3KraWlU/nOTIJKf39t89yYWLGhzz06/jb7aqv8X9AAAAhmVP1foXJvmHJDvSnST41dbalb39T0zyvsUMjXlqs7b6C/4AAACDsmnwb619sqrumeRhSb7UWvvw1CFvS/KZRQ2O+VnT6j+1b4s5/gAAAIO1x/n5rbXLkvzfDfb97XrbOfjMvLifij8AAMCg7GmOPwPRj/PTFf/+HH/BHwAAYFgE/5FwOT8AAIBxEvxHQqs/AADAOAn+I7Gm1X+Ty/kJ/gAAAMOyx8X9plXVbTJ1wqC1dsXcRsRCzHw5P63+AAAAgzJT8K+qOyd5XZJHJtne35WumLw095ExV8szBv8VFX8AAIBBmbXi/4dJbpPk6UkuydrOcQ4B/Yq/Vf0BAADGY9bg/5Ak39xa+9QiB8NitKkwPz3Hf4vF/QAAAAZr1sX9vpDkVoscCIuz2Yr+iTn+AAAAQzZr8H9OkpdV1d0WORgWo1/DXy/4b5ma4z/dIQAAAMCha9ZW//+bruL/uaq6McnO/s7W2jHzHhjzs6eKf1VlS9Wu41ZaW9MFAAAAwKFr1uD/7IWOgoVa2WRhv1VLW7ZkZXk5STfP32UaAAAAhmGm4N9ae/OiB8LirFnRf4NK/lJVbp7cXl5ZSZZEfwAAgCGYteK/S1V9XZLt/W2ttQvmNiLmrl/x36iFf8nK/gAAAIM0U/Cvqlsn+a0kP5Sp0D+hPHwQ66/Tv2HFf8vX1nkU/AEAAIZj1lX9X5nkm5J8b5IbkvxIkp9NclGSJyxmaMxLm2WOv0v6AQAADNKsrf6PTfLDrbUPVtVyko+21t5eVV9M8t+S/PnCRsg+29Oq/sna4L+i4g8AADAYs1b8b5Pk/Mntq5IcO7n9L0n+w7wHxXzNEvy3mOMPAAAwSLMG/88nucvk9meTPLG6yeLfn+SKRQyM+enH+M0u57dK8AcAABiOWYP/m5J84+T2r6Vr778pySuS/Pr8h8U87W2rvzn+AAAAwzHTHP/W2qt7t0+vqnskeVCSs1tr/7qowTEfbW+Dv4o/AADAYMy6uN8arbULklww57GwIMuzBP9eq7/F/QAAAIZj1lb/VNWzqurTVXV9Vd1lsu15VfVDixse87Bmjv8MFf+dWv0BAAAGY6bgX1X/M8kvJnl91q4Pd3GSZy9gXMzRLK3+VvUHAAAYplkr/s9M8hOttdck2dnb/rEk9577qJirNYv7bXDM1v6q/ir+AAAAgzFr8L9zkk+ts/3mJIfPbzgsQj/4z9LqL/YDAAAMx6zB/9wkD1hn+39K8pn5DYdF6Dfuz9Tqr+IPAAAwGLOu6v/KJL9TVUekm+P/LVX15CQ/l+THFzU45mPF5fwAAABGa6bg31r7w6ramuRXkxyR5C1JLknyP1prb1/g+JiDNa3+GxzTv5yf4A8AADAcs1b801p7Q5I3VNVxSba01r6yuGExT7O0+i9p9QcAABikmYP/qtbaZYsYCIuzt63+Kyr+AAAAg7Fp8K+q02Z5ktba98xnOCzCLK3+W8zxBwAAGKQ9Vfz/S5Lzk7xv8UNhUdosFX9z/AEAAAZpT8H/FUmenOQRSf4wyZtaaxctfFTM1V6v6m+OPwAAwGBs2Wxna+3nk9wpyXOTPCjJ2VX1d1X1+Kratj8GyL7rx/hyOT8AAIBR2TT4J0lrbbm1dlpr7XuTnJLkvUl+JcnFVXXUogfIvpup4t9v9VfxBwAAGIw9Bv8pRya5TZKjklybtVeK4yDVZljcT8UfAABgmPYY/Kvq8Kp6alV9IMm/Jrlzkqe21u7SWrtu4SNkn+11xV/wBwAAGIw9Xc7vDUl+KMnZSf4gyfe01r66PwbG/FjcDwAAYLz2tKr/05NckOSLSR6b5LHrLQ7XWvue+Q+NeenX72dp9V9R8QcAABiMPQX/P4p5/Ie8/ge4UcV/izn+AAAAg7Rp8G+tPW0/jYMF6rfum+MPAAAwLnu7qj+HoDWt/ub4AwAAjIrgPwL9y/lt9IG7nB8AAMAwCf4j4HJ+AAAA4yX4j0A/+G/U6r9Fqz8AAMAgCf4jMMuq/lu1+gMAAAyS4D8CWv0BAADGS/AfgTWt/hsc01/cb0XwBwAAGAzBfwRmqfib4w8AADBMgv8IzDLH3+X8AAAAhknwH4GZWv3N8QcAABikgyr4V9VjqupzVXVOVT1vnf23qqq3T/Z/uKpO7u17/mT756rqu/bnuA92My3up9UfAABgkA6a4F9VS0lem+SxSe6V5Ier6l5Thz09yZWttbsleXWSX5889l5Jnpjk3kkek+R3J89H9r7V3+J+AAAAw3HQBP8kD0lyTmvt3NbaTUneluRxU8c8LsmbJ7f/PMm3V1VNtr+ttXZja+0LSc6ZPB+ZavWfYXG/nSr+AAAAg3EwBf8TklzYu3/RZNu6x7TWdia5KsmxMz52tGZq9TfHHwAAYJAOpuC/X1TVM6rqzKo689JLLz3Qw9kv2gyL+23V6g8AADBIB1PwvzjJnXr3T5xsW/eYqtqa5NZJLp/xsUmS1trrW2sPaq096Pjjj5/T0A9u/SC/pOIPAAAwKgdT8D8jyalVdUpVbU+3WN9pU8ecluSpk9uPT3J668rZpyV54mTV/1OSnJrkI/tp3Ae9vZ3jb1V/AACA4dh6oAewqrW2s6qeneRdSZaSvLG19umqekmSM1trpyX5gyRvqapzklyR7uRAJsf9WZLPJNmZ5L+31pYPyC9yEOrX7zdq9V9zOT8VfwAAgME4aIJ/krTW3pnknVPbXti7fUOSH9zgsS9N8tKFDvAQNdPifoI/AADAIB1Mrf4syF6v6q/VHwAAYDAE/xFY0+o/Q8Vf7AcAABgOwX8E1lT8NzjG4n4AAADDJPiPQDPHHwAAYLQE/xGY5XJ+t2SOf3OCAAAA4KAn+I9AP8bPo+J/0TXX5L++61358b//+1x8zTXzGCIAAAALIviPwEyt/v2K/ybBf3llJa8688x8+brrctmOHTn9ggvmN1AAAADmTvAfgTWt/hscszTj4n6nff7zOfvKK3fdv/yGG/Z5fAAAACyO4D8CK3Na3O+L116bP/7MZ9Zs+6rgDwAAcFAT/EegH+NnafVfWSf4t9by22edlZuWl9dsv/LGG+cyRgAAABZD8B+BeVT8///zzsu/XnrpbtuvVPEHAAA4qAn+IzDLHP+q2nWpv9babpfqe8c55+y6/bi73W3X7atuvHHdDgEAAAAODoL/CMzS6p9sXPW/aXk5F197bZLuBMGP3uteOXr79iTdSYVrbrppvgMGAABgbgT/EZil1X96X39l/0uuvXZXB8DXHXlkDtu6Nbe51a127dfuDwAAcPAS/Afq7CuvzF+dfXa+esMNa1v9b0HF/8Jrrtl1+8SjjkqS3Paww3ZtE/wBAAAOXlsP9ACYvyt27MgLPvjB3LBzZz7xla/sastPNp7jn6xd2X+j4H+no49OkrUVfyv7AwAAHLRU/Afo/RddlBt27kySfPzSS7NjcjtZW9WftrRBq/+FV1+96/adjjkmyS2v+E9fDhAAAIDFEvwH6H0XXrjr9vLKSj57xRW77u9rq/9qxf+WBP8//sxn8oOnnZbXnnXWTMcDAACw7wT/Q8Dyykq+ct11+eSll+bd552Xf7nkkg0r5+dfdVXO/epX12y7uteKP3Or/6Tiv7yysmtF/+SWz/FvreWvzj47K63lXeedl+tvvnmPjwEAAGDfmeN/kHvxP/1TPn7ppWta75Pkzscck+c99KE5cVKBX9Wv9q9nby/n9+Xrr8/OyWvf7rDDcuRkvYDb9ub4f7V3YuH6m2/OP1xwQe58zDH5xuOP37X92ptv3nWyok0uAXjEtm2bjhUAAIB9p+J/kFvasmW30J8k5199dZ773vfm/b2g31rbt+Dfq/ivXglgTZv/ZH5/snHF/08++9m8/hOfyC/94z/mS9ddt2v75Tt2rHmta266adNxAgAAMB+C/0HuDkcckaQL2ve43e3ysBNOyLalpSTJDTt35pVnnJHfPeus7FxZyacuuyyXTQL20du35w5HHrnb820W/PtfhtWK/5qF/XrdBf3g36/4f+IrX0nSnTj4997aAldMTQe4Vqs/AADAfqHV/yD3pHveM0+7z32yfRL2k+QLX/1qfu0jH8klk7n3f/eFL+S8q69ec4m9h594Ym5eWcm7e1X3ZO/n+F/Um9/fD/5Hb9+eqtrVtn/z8nKWtmzJJb3Xu6xX5Z9eB0DFHwAAYP9Q8T/IHbl9+5rQnySn3OY2+c1HPSoPP/HEXds+e/nl+ZdLLtl1/z+edFLuc9xxuz3f3s7x71f8++sJbKlac6LhqhtvzFeuvz439xYd7Ad/rf4AAAAHhuB/iDp827b87IMfnB+/7313u0Tf1x91VO5+29vmPsceu9vj9ib4t9bWvZTfqjXz/G+8MRf1jk2Sy3tV/t1a/QV/AACA/ULwP4RVVb7v1FPzom/5lhzZWyH/UXe6U6oqxx9xRI47/PDdHrOR6cX9Lt+xIzt27kySHLlt25oKf7J2Zf8rb7hht+B/2fXX77o9HfyvMccfAABgvxD8B+CBX/d1edWjHpVvueMd8213ulO+79RTk3Qhf7rdf9aK/86VlTXz+0865pjdThrcZmpl/4t7xydrW/13C/4q/gAAAPuFxf0G4o5HHZUXfPM377b93scdt+YSf5ud6dky1erfb/M/carNP5mq+K/T6n/ljTdmeWUlS1u2aPUHAAA4QFT8B+6+UxX/zVr9t06t6r/RpfxWrbmk3w03rDlRkCSttVx5ww27/tt3teAPAACwXwj+A3fHo47KrXuV+Vlb/Vf2sLBfsjb4X3jNNbnqxht3O+byG27INTfdlJ2TywOuUvEHAADYPwT/gauqfPtJJyXpFug75da33vDYzVr91wv+/cX+/u2KK9Z9zst27NitzT+xuB8AAMD+Yo7/CDz53vfO/e9wh5x09NE5bOvGH3l/Vf/PXXHFrgr+9qWl3P6II3Y7vl/xv2l5ed3nvGzHjhy2tLTb9mtvuimttU2nHgAAALDvBP8R2LplS+53+9vv8bh+q/+f//u/77p94tFHrxvQbzt1eb9Vt1payo2TEwGX79iRI9Y52bBzZSU3Li9veiICAACAfafVn12WNqi+/8fJVIFpR2zblm3rVPP7lxC8bMeO3Rb2W+WSfgAAAIun3Mou/Uv2bV9aysNOOCGPPeWU3PPYY9c9vqpy21vdKl+5/vo127/p9rfPR7/85SRdxf/o7dvXffw1N92U49eZQgAAAMD8CP7s8v2nntpV8bdsybeecEKO2iCw9932sMN2C/7fePzxu25ftmNHjtlgSsC1FvgDAABYOMGfXbYtLeW773rXvXrMbaZC/XGHH54Tjjpq1/0rbrght96xY9f9W9/qVrsWDdTqDwAAsHjm+LNP+iv7J910gcO2bt3VLbBzZSXnX331rv13PuaYXbcFfwAAgMUT/Nkn0xX/1XUCjjv88F3b+pf6E/wBAAD2L8GffbJbxX/S5n/s1PYkOWr79tyut13wBwAAWDzBn32yXqt/srbiv+p2hx22ZsFAi/sBAAAsnuDPPrntVKv/6sJ+x24Q/PuX9lPxBwAAWDzBn33Sb90/bOvWXYF/o4p/P/hfK/gDAAAsnODPPjn+iCNyn+OOS5J818knp6qSbFLx37Zt130VfwAAgMXbeqAHwKGtqvKrD394vnL99bnDkUfu2r5uxf/ww7X6AwAA7Gcq/uyzqloT+pP1V/W3uB8AAMD+J/izEEds25bDtq5tKLndYYflVktL2bql+9rdtLycm5aXD8TwAAAARkPwZyGqard5/scedliqSrs/AADAfiT4szDT8/xvM2n/P8oCfwAAAPuN4M/C9IP/0du3Z/vS0q7bqwR/AACAxRL8WZj+An+3690W/AEAAPYfwZ+F6Vf8b9sL/lb2BwAA2H8Efxbmnsceu+v2vXq3VfwBAAD2n617PgRumZNvfev8r4c9LF+67rp8+0kn7dp+dG9xv2sFfwAAgIUS/FmoB9zhDrttU/EHAPh/7d17sF3VfR/w709XSEQST4OFABMBlh/YNCSWbWonHmxjg5M0JMRtnNou9aO4E3smTdIZaOvGadN27LZJ3GRsHEIIeGqTxm4daONCgIkf7YANtrExqBTMG4TAEMFFIAlJq3/cze3Rja5e6N59zrmfz8yZs/fa+5zzu5o1W/d719rrAMwfU/2ZdzsFf/f4AwAAzCnBn3m30+J+RvwBAADmlODPvDPVHwAAYP4I/sy7wcX9BH8AAIC5Jfgz71YY8QcAAJg3gj/z7kcWL86iqiTJlu3bs3X79p4rAgAAGF+CP/Ouqna6z98CfwAAAHNH8KcXO63s7yv9AAAA5ozgTy8s8AcAADA/BH96cYgRfwAAgHkh+NOLQ6zsDwAAMC8Ef3px+NKl09uPbNrUYyUAAADjTfCnF6sPO2x6++6NG3usBAAAYLwJ/vTi5MMPn97+geAPAAAwZwR/enHcihVZMjGRJHli8+Y8uWVLzxUBAACMJ8GfXkwsWpTVhx46vW+6PwAAwNwQ/OnNSab7AwAAzDnBn94M3ud/95NP9lgJAADA+BL86c1Jgyv7C/4AAABzQvCnN6sPOyyLqpIkDz/9dDZv29ZzRQAAAONH8Kc3SyYmcvwhhyRJWmu5x6g/AADAASf406uTLfAHAAAwpwR/euU+fwAAgLkl+NMrX+kHAAAwtwR/ejU44n//U09l244dPVYDAAAwfgR/erViyZK8eNmyJMm2HTty/1NP9VwRAADAeBmK4F9VR1bVtVV1Z/d8xCznndedc2dVnTfQ/pWquqOqbukeL56/6nmhBhf4c58/AADAgTUUwT/JhUmub62tSXJ9t7+TqjoyyceSvD7J65J8bMYfCN7dWjutezw6H0VzYAze5//tDRvyzHPP9VgNAADAeFncdwGdc5Kc0W1fnuQrSS6Ycc5ZSa5trT2RJFV1bZKzk1wxPyUyV04euM//6w8+mBsefjivOuqo/NzJJ+d1q1b1WBkAAMDoG5YR/5WttfXd9iNJVu7inOOSPDCw/2DX9rw/6ab5/8uqqjmqkzlwyotelBVLlkzvb9uxI9999NH82xtvzOPPPttjZQAAAKNv3oJ/VV1XVd/fxeOcwfNaay1J28e3f3dr7dQkP9U93rubOs6vqpur6ubHHntsn38ODrzlS5bkP735zXnXK16x0/3+O1rLHU880WNlAAAAo2/egn9r7czW2qt38bgyyYaqWpUk3YbECJ0AABBiSURBVPOu7tF/KMlLBvaP79rSWnv+eTLJ5zO1BsBsdVzcWlvbWlt79NFHH5gfjhfsxcuX592nnJJPvuUtOeelL51uv9cq/wAAAC/IsEz1vyrJ86v0n5fkyl2cc02St1fVEd2ifm9Pck1VLa6qo5Kkqg5K8rNJvj8PNTNHThy45/8+wR8AAOAFGZbg//Ekb6uqO5Oc2e2nqtZW1SVJ0i3q99tJbuoe/7prW5qpPwB8L8ktmZoF8Efz/yNwoPzooYdOb9/r6/0AAABekKFY1b+19niSt+6i/eYkHxzYvzTJpTPO2ZTkNXNdI/PnhEMPTVWltZb1mzZly7ZtWbp4KLoqAADAyBmWEX+YtmRiIseuWJEkaa3l/snJnisCAAAYXYI/Q2lwur/7/AEAAPaf4M9QWu0+fwAAgANC8GcoGfEHAAA4MAR/htLqga/0u1fwBwAA2G+CP0PpmOXLs3RiIkmycfPmPLllS88VAQAAjCbBn6G0qConmO4PAADwggn+DK3B6f73WOAPAABgvwj+DC0L/AEAALxwgj9Dy1f6AQAAvHCCP0NrcKr//U89ldZaj9UAAACMJsGfoXXY0qU5bOnSJMmW7dvzyKZNPVcEAAAwegR/htrgqP+97vMHAADYZ4I/Q221Bf4AAABeEMGfoXbCQPB/cHKyx0oAAABGk+DPUDt2+fLp7fVPP91jJQAAAKNJ8GeorVqxYnp7vcX9AAAA9pngz1A78uCDs2RiIkkyuXVrJrdu7bkiAACA0SL4M9SqKqsGpvv7Sj8AAIB9I/gz9Haa7u8+fwAAgH0i+DP0Bkf83ecPAACwbwR/ht6xFvgDAADYb4I/Q29wxP9hU/0BAAD2ieDP0DPVHwAAYP8J/gy9o5Yty+JFU1114+bNefa553quCAAAYHQI/gy9RVU5xqg/AADAfhH8GQmm+wMAAOwfwZ+RsNPK/hb4AwAA2GuCPyNhcKr/w0b8AQAA9prgz0jYaaq/EX8AAIC9JvgzEnaa6m/EHwAAYK8J/oyEo5cty6KqJMnjzz6bLdu29VwRAADAaBD8GQmLFy3KyoHp/o8Y9QcAANgrgj8jw1f6AQAA7DvBn5Eh+AMAAOw7wZ+RsWpggb+HrewPAACwVwR/RsaxRvwBAAD2meDPyBgc8V9vxB8AAGCvCP6MjJXLlqW6r/R7zFf6AQAA7BXBn5Fx0MREju1G/VtredCoPwAAwB4J/oyUEw45ZHr7/qee6rESAACA0SD4M1JOOPTQ6W3BHwAAYM8Ef0bKTiP+k5M9VgIAADAaBH9GihF/AACAfSP4M1KOW7FiemX/Dc88Y2V/AACAPRD8GSkzV/Z/wHR/AACA3RL8GTmD9/kL/gAAALsn+DNy3OcPAACw9wR/Rs7giP99gj8AAMBuCf6MnJ1G/E31BwAA2C3Bn5EzuLL/o888k81W9gcAAJiV4M/Imbmy/4NG/QEAAGYl+DOSBu/zN90fAABgdoI/I2nwPv8HLPAHAAAwK8GfkWRlfwAAgL0j+DOSrOwPAACwdwR/RtLgyv4bNm2ysj8AAMAsBH9G0uDK/kny53fdJfwDAADsguDPyDpxYLr/526/Pe+/+upcsW5dtu3Y0WNVAAAAw0XwZ2Sd+7KX5YiDD57en9y6NZ9fty6f+s53eqwKAABguAj+jKw1RxyRS846K79y2mk5Zvny6fbr7rsvP9i4scfKAAAAhofgz0hbMjGRd5x0Uj7ztrfltcccM91+6a23prXWY2UAAADDQfBnLEwsWpT3n3pqFnUr/X/vscfy7Q0beq4KAACgf4I/Y+P4Qw7J21evnt6/7LbbssOoPwAAsMAJ/oyVv//KV+bgxYuTJPc++WS+fPfdVvkHAAAWtMV9FwAH0hEHH5xfWLMmV6xblyT5w+9+N5fcemuOXb48L162LAdNTGTJokXTz0smJnLQjOfFi/w9DAAAFqqVy5blNQPrh40DwZ+xc+6aNfmf99yTjZs3J0m279iRByYn88DkZM+VAQAAw+70Y48du+BvaJOxc/Dixfno6afntccck6OXLeu7HAAAgF4Z8WcsvfzII/Obb3hDkuTZ557L/ZOTmdy6NVu3b89zO3bs9DyzzZoAAACwcJ142GF9l3DACf6MvR856KC8/Mgj+y4DAACgF6b6AwAAwBgT/AEAAGCMCf4AAAAwxgR/AAAAGGOCPwAAAIwxwR8AAADGmOAPAAAAY0zwBwAAgDEm+AMAAMAYE/wBAABgjAn+AAAAMMaGIvhX1ZFVdW1V3dk9HzHLeVdX1caq+h8z2k+sqm9U1V1V9V+qasn8VA4AAADDbSiCf5ILk1zfWluT5Ppuf1f+Q5L37qL9E0l+r7X20iR/neQDc1IlAAAAjJhhCf7nJLm82748yc/v6qTW2vVJJgfbqqqSvCXJF/f0egAAAFhohiX4r2ytre+2H0mych9e+6IkG1tr27r9B5McdyCLAwAAgFG1eL4+qKquS3LMLg79i8Gd1lqrqjaHdZyf5PwkOeGEE+bqYwAAAGAozFvwb62dOduxqtpQVataa+uralWSR/fhrR9PcnhVLe5G/Y9P8tBu6rg4ycVJsnbt2jn7AwMAAAAMg2GZ6n9VkvO67fOSXLm3L2yttSR/leSd+/N6AAAAGGfDEvw/nuRtVXVnkjO7/VTV2qq65PmTqurrSb6Q5K1V9WBVndUduiDJr1fVXZm65/+P57V6AAAAGFLzNtV/d1prjyd56y7ab07ywYH9n5rl9Xcned2cFQgAAAAjalhG/AEAAIA5IPgDAADAGKuptfEWpqp6LMl9fdexl45K8sO+i4Dd0EcZdvoow04fZdjpowy7hdZHf7S1dvTenLigg/8oqaqbW2tr+64DZqOPMuz0UYadPsqw00cZdvro7Ez1BwAAgDEm+AMAAMAYE/xHx8V9FwB7oI8y7PRRhp0+yrDTRxl2+ugs3OMPAAAAY8yIPwAAAIwxwX/IVdXZVXVHVd1VVRf2XQ8kSVXdW1W3VtUtVXVz13ZkVV1bVXd2z0f0XScLS1VdWlWPVtX3B9p22S9ryu9319bvVdVP9Fc5C8UsffS3quqh7np6S1X99MCxf9b10Tuq6qx+qmahqKqXVNVfVdXtVXVbVf1q1+46ytDYTT91Ld0DwX+IVdVEkk8leUeSU5L8clWd0m9VMO3NrbXTBr4y5cIk17fW1iS5vtuH+XRZkrNntM3WL9+RZE33OD/JRfNUIwvbZfmbfTRJfq+7np7WWvtyknT/378ryau613y6+70A5sq2JL/RWjslyelJPtz1Q9dRhsls/TRxLd0twX+4vS7JXa21u1trW5P8aZJzeq4JZnNOksu77cuT/HyPtbAAtda+luSJGc2z9ctzkny2TbkxyeFVtWp+KmWhmqWPzuacJH/aWtvSWrsnyV2Z+r0A5kRrbX1r7dvd9mSSdUmOi+soQ2Q3/XQ2rqUdwX+4HZfkgYH9B7P7jg3zpSX5y6r6VlWd37WtbK2t77YfSbKyn9JgJ7P1S9dXhslHuqnSlw7cJqWP0puqWp3kx5N8I66jDKkZ/TRxLd0twR/YHz/ZWvuJTE3z+3BVvWnwYJv6uhBfGcJQ0S8ZUhclOTnJaUnWJ/mdfsthoauqFUn+a5J/0lp7avCY6yjDYhf91LV0DwT/4fZQkpcM7B/ftUGvWmsPdc+PJvlSpqZMbXh+il/3/Gh/FcK02fql6ytDobW2obW2vbW2I8kf5f9PQdVHmXdVdVCmwtTnWmv/rWt2HWWo7KqfupbumeA/3G5KsqaqTqyqJZlamOKqnmtigauq5VV1yPPbSd6e5PuZ6pvndaedl+TKfiqEnczWL69K8g+6ValPT/LkwFRWmDcz7on+hUxdT5OpPvquqlpaVSdmagG1b853fSwcVVVJ/jjJutba7w4cch1laMzWT11L92xx3wUwu9batqr6SJJrkkwkubS1dlvPZcHKJF+auu5mcZLPt9aurqqbkvxZVX0gyX1J/l6PNbIAVdUVSc5IclRVPZjkY0k+nl33yy8n+elMLfLzTJL3zXvBLDiz9NEzquq0TE2fvjfJh5KktXZbVf1ZktsztYr1h1tr2/uomwXjjUnem+TWqrqla/vncR1luMzWT3/ZtXT3aupWHQAAAGAcmeoPAAAAY0zwBwAAgDEm+AMAAMAYE/wBAABgjAn+AAAAMMYEfwBgj6qqVdU75/D913afsXquPgMAFirBHwDGXFVd1oXqmY8b9+FtViX573NVIwAwdxb3XQAAMC+uS/LeGW1b9/bFrbVHDmw5AMB8MeIPAAvDltbaIzMeTyTT0/g/UlV/UVXPVNV9VfWewRfPnOpfVb/Znbelqh6pqs8OHFtaVZ+sqg1Vtbmqbqyqn5zxfmdX1f/pjn89yctmFlxVb6iqr3Y1PVRVF1XVoQPH39S999NV9WRVfbOqXn0A/80AYCwI/gBAkvyrJFclOS3JxUk+W1Vrd3ViVf1ikn+a5FeSrEnys0m+OXDKv0/yS0nen+THk9ya5OqqWtW9/iVJ/jzJtd3n/UH3msHPODXJX3Y1/ViSc7tzL+2OL05yZZL/1R1/fZJPJtm+//8EADCeqrXWdw0AwByqqsuSvCfJ5hmHPtVau6CqWpJLWmv/aOA11yV5pLX2nm6/Jfm7rbUvVtWvJ/lQkle31p6b8VnLk/x1kg+21j7btU0k+b9JrmitfbSq/l2SdyZ5eet+Eamqjyb57SQnttbu7WYQPNda+8DAe5+W5DtJVibZluTxJGe01r56AP6ZAGBsuccfABaGryU5f0bbxoHtG2YcuyHJz8zyXl9I8qtJ7qmqa5JcneSq1tqWJCcnOSjJ/37+5Nba9qq6IckpXdMrk9zYdh59mPn5r0ny0qr6pYG26p5Pbq3d0P1B45qquj7J9Um+2Fq7f5aaAWDBMtUfABaGZ1prd814/HB/3qi19kCSl2dq1P+pJL+T5FvdaP9uX7oPH7MoySWZmt7//OPHMnVrwS1dHe/L1BT/ryX5uSR3VNVZ+/AZALAgCP4AQJKcvov9dbOd3Frb3Fr7i9baryV5bZJXJXljkh9k6tsC3vj8ud1U/7+d5PauaV2S11dVDbzlzM//dpJX7eKPFXe11p4dqOO7rbVPtNbOSPKVJOft9U8MAAuEqf4AsDAsrapjZrRtb6091m2fW1U3ZSo8vzPJWzM1mv43VNU/zNTvEN9I8nSmFvJ7LsmdrbVNVXVRkk9U1Q+T3JPk1zJ1X/6nu7f4TJLfSPLJqvp0klOT/OMZH/OJJDdW1WeS/GGSySSvSPJ3WmsfqqoTMzXj4KokDyU5KcnfSnLRvvyjAMBCIPgDwMJwZpL1M9oeSnJ8t/1bSX4xye8neSzJ+1prN83yXhuTXJDkP2bqfv7bk5zbWrunO35B9/wnSQ7P1IJ8Z7fW1idJa+3+qjo3ye9mKrx/K8mFSf7z8x/QWvteVb0pyb9J8tUkE0nuTvKl7pRnMvUVgF9IclSSDUk+l6k/GAAAA6zqDwAL3OCK/X3XAgAceO7xBwAAgDEm+AMAAMAYM9UfAAAAxpgRfwAAABhjgj8AAACMMcEfAAAAxpjgDwAAAGNM8AcAAIAxJvgDAADAGPt/KH857sVt5qgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1224x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mp.figure(figsize=(17,10))\n",
    "mp.title('PPO BoxWorld Agent Training Loss, {} Episodes'.format(episode), size=14)\n",
    "mp.xlabel('Episodes', size=14),mp.ylabel('Mean Squared Error', size=14)\n",
    "mp.plot(losses, lw=3, color='darkcyan', alpha=7e-1)\n",
    "mp.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
